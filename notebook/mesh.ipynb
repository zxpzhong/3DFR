{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.11 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "a5593312ab51e25650935ca88ad30522998c2cd96b9450ce2306a089b22e08ef"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# 1. mesh读取测试"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kaolin as kal\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "import os\n",
    "from packaging import version\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from packaging import version\n",
    "\n",
    "def grid_sample_bilinear(input, grid):\n",
    "    # PyTorch 1.3 introduced an API change (breaking change in version 1.4), therefore we check this explicitly\n",
    "    # to make sure that the behavior is consistent across different versions\n",
    "    if version.parse(torch.__version__) < version.parse('1.3'):\n",
    "        return F.grid_sample(input, grid, mode='bilinear')\n",
    "    else:\n",
    "        return F.grid_sample(input, grid, mode='bilinear', align_corners=True)\n",
    "\n",
    "\n",
    "def symmetrize_texture(x):\n",
    "    # Apply even symmetry along the x-axis (from length N to 2N)\n",
    "    # 先沿最后一个维度反转\n",
    "    x_flip = torch.flip(x, (len(x.shape) - 1,))\n",
    "    # 翻转后，将原来最后一维（列），向左和向右分别复制一半，这样拓宽多出一倍\n",
    "    return torch.cat((x_flip[:, :, :, x_flip.shape[3]//2:], x, x_flip[:, :, :, :x_flip.shape[3]//2]), dim=-1)\n",
    "\n",
    "\n",
    "def adjust_poles(tex):\n",
    "    # Average top and bottom rows (corresponding to poles) -- for mesh only\n",
    "    top = tex[:, :, :1].mean(dim=3, keepdim=True).expand(-1, -1, -1, tex.shape[3])\n",
    "    middle = tex[:, :, 1:-1]\n",
    "    bottom = tex[:, :, -1:].mean(dim=3, keepdim=True).expand(-1, -1, -1, tex.shape[3])\n",
    "    return torch.cat((top, middle, bottom), dim=2)\n",
    "    \n",
    "\n",
    "def circpad(x, amount=1):\n",
    "    # Circular padding along x-axis (before a convolution)\n",
    "    left = x[:, :, :, :amount]\n",
    "    right = x[:, :, :, -amount:]\n",
    "    return torch.cat((right, x, left), dim=3)\n",
    "\n",
    "\n",
    "def qrot(q, v):\n",
    "    \"\"\"\n",
    "    Quaternion-vector multiplication (rotation of a vector)\n",
    "    \"\"\"\n",
    "    assert q.shape[-1] == 4\n",
    "    assert v.shape[-1] == 3\n",
    "    \n",
    "    qvec = q[:, 1:].unsqueeze(1).expand(-1, v.shape[1], -1)\n",
    "    uv = torch.cross(qvec, v, dim=2)\n",
    "    uuv = torch.cross(qvec, uv, dim=2)\n",
    "    return v + 2 * (q[:, :1].unsqueeze(1) * uv + uuv)\n",
    "\n",
    "def qmul(q, r):\n",
    "    \"\"\"\n",
    "    Quaternion-quaternion multiplication\n",
    "    \"\"\"\n",
    "    assert q.shape[-1] == 4\n",
    "    assert r.shape[-1] == 4\n",
    "    \n",
    "    original_shape = q.shape\n",
    "    \n",
    "    # Compute outer product\n",
    "    terms = torch.bmm(r.view(-1, 4, 1), q.view(-1, 1, 4))\n",
    "\n",
    "    w = terms[:, 0, 0] - terms[:, 1, 1] - terms[:, 2, 2] - terms[:, 3, 3]\n",
    "    x = terms[:, 0, 1] + terms[:, 1, 0] - terms[:, 2, 3] + terms[:, 3, 2]\n",
    "    y = terms[:, 0, 2] + terms[:, 1, 3] + terms[:, 2, 0] - terms[:, 3, 1]\n",
    "    z = terms[:, 0, 3] - terms[:, 1, 2] + terms[:, 2, 1] + terms[:, 3, 0]\n",
    "    return torch.stack((w, x, y, z), dim=1).view(original_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MeshTemplate:\n",
    "    \n",
    "    def __init__(self, mesh_path, is_symmetric=True):\n",
    "        \n",
    "        MeshTemplate._monkey_patch_dependencies()\n",
    "        \n",
    "        mesh = kal.rep.TriangleMesh.from_obj(mesh_path, enable_adjacency=True)\n",
    "        mesh.cuda()\n",
    "        \n",
    "        print('---- Mesh definition ----')\n",
    "        print(f'Vertices: {mesh.vertices.shape}')\n",
    "        print(f'Indices: {mesh.faces.shape}')\n",
    "        print(f'UV coords: {mesh.uvs.shape}')\n",
    "        print(f'UV indices: {mesh.face_textures.shape}')\n",
    "\n",
    "        poles = [mesh.vertices[:, 1].argmax().item(), mesh.vertices[:, 1].argmin().item()] # North pole, south pole\n",
    "\n",
    "        # Compute reflection information (for mesh symmetry)\n",
    "        axis = 0\n",
    "        if version.parse(torch.__version__) < version.parse('1.2'):\n",
    "            neg_indices = torch.nonzero(mesh.vertices[:, axis] < -1e-4)[:, 0].cpu().numpy()\n",
    "            zero_indices = torch.nonzero(torch.abs(mesh.vertices[:, axis]) < 1e-4)[:, 0].cpu().numpy()\n",
    "        else:\n",
    "            neg_indices = torch.nonzero(mesh.vertices[:, axis] < -1e-4, as_tuple=False)[:, 0].cpu().numpy()\n",
    "            zero_indices = torch.nonzero(torch.abs(mesh.vertices[:, axis]) < 1e-4, as_tuple=False)[:, 0].cpu().numpy()\n",
    "            \n",
    "        pos_indices = []\n",
    "        for idx in neg_indices:\n",
    "            opposite_vtx = mesh.vertices[idx].clone()\n",
    "            opposite_vtx[axis] *= -1\n",
    "            dists = (mesh.vertices - opposite_vtx).norm(dim=-1)\n",
    "            minval, minidx = torch.min(dists, dim=0)\n",
    "            # assert minval < 1e-4, minval\n",
    "            pos_indices.append(minidx.item())\n",
    "        # assert len(pos_indices) == len(neg_indices)\n",
    "        # assert len(pos_indices) == len(set(pos_indices)) # No duplicates\n",
    "        pos_indices = np.array(pos_indices)\n",
    "\n",
    "        pos_indices = torch.LongTensor(pos_indices).cuda()\n",
    "        neg_indices = torch.LongTensor(neg_indices).cuda()\n",
    "        zero_indices = torch.LongTensor(zero_indices).cuda()\n",
    "        nonneg_indices = torch.LongTensor(list(pos_indices) + list(zero_indices)).cuda()\n",
    "\n",
    "        total_count = len(pos_indices) + len(neg_indices) + len(zero_indices)\n",
    "        # assert total_count == len(mesh.vertices), (total_count, len(mesh.vertices))\n",
    "\n",
    "        index_list = {}\n",
    "        segments = 32\n",
    "        rings = 31 if '31rings' in mesh_path else 16\n",
    "        print(f'The mesh has {rings} rings')\n",
    "        print('-------------------------')\n",
    "        for faces, vertices in zip(mesh.face_textures, mesh.faces):\n",
    "            for face, vertex in zip(faces, vertices):\n",
    "                if vertex.item() not in index_list:\n",
    "                    index_list[vertex.item()] = []\n",
    "                res = mesh.uvs[face].cpu().numpy() * [segments, rings]\n",
    "                if math.isclose(res[0], segments, abs_tol=1e-4):\n",
    "                    res[0] = 0 # Wrap around\n",
    "                index_list[vertex.item()].append(res)\n",
    "\n",
    "        topo_map = torch.zeros(mesh.vertices.shape[0], 2)\n",
    "        for idx, data in index_list.items():\n",
    "            avg = np.mean(np.array(data, dtype=np.float32), axis=0) / [segments, rings]\n",
    "            topo_map[idx] = torch.Tensor(avg)\n",
    "\n",
    "        # Flip topo map\n",
    "        topo_map = topo_map * 2 - 1\n",
    "        topo_map = topo_map * torch.FloatTensor([1, -1]).to(topo_map.device)\n",
    "        topo_map = topo_map.cuda()\n",
    "        nonneg_topo_map = topo_map[nonneg_indices]\n",
    "\n",
    "        # Force x = 0 for zero-indices if symmetry is enabled\n",
    "        symmetry_mask = torch.ones_like(mesh.vertices).unsqueeze(0)\n",
    "        symmetry_mask[:, zero_indices, 0] = 0\n",
    "\n",
    "        # Compute mesh tangent map (per-vertex normals, tangents, and bitangents)\n",
    "        mesh_normals = F.normalize(mesh.vertices, dim=1)\n",
    "        up_vector = torch.Tensor([[0, 1, 0]]).to(mesh_normals.device).expand_as(mesh_normals)\n",
    "        mesh_tangents = F.normalize(torch.cross(mesh_normals, up_vector, dim=1), dim=1)\n",
    "        mesh_bitangents = torch.cross(mesh_normals, mesh_tangents, dim=1)\n",
    "        # North pole and south pole have no (bi)tangent\n",
    "        mesh_tangents[poles[0]] = 0\n",
    "        mesh_bitangents[poles[0]] = 0\n",
    "        mesh_tangents[poles[1]] = 0\n",
    "        mesh_bitangents[poles[1]] = 0\n",
    "        \n",
    "        tangent_map = torch.stack((mesh_normals, mesh_tangents, mesh_bitangents), dim=1).cuda()\n",
    "        nonneg_tangent_map = tangent_map[nonneg_indices] # For symmetric meshes\n",
    "        \n",
    "        self.mesh = mesh\n",
    "        self.topo_map = topo_map\n",
    "        self.nonneg_topo_map = nonneg_topo_map\n",
    "        self.nonneg_indices = nonneg_indices\n",
    "        self.neg_indices = neg_indices\n",
    "        self.pos_indices = pos_indices\n",
    "        self.symmetry_mask = symmetry_mask\n",
    "        self.tangent_map = tangent_map\n",
    "        self.nonneg_tangent_map = nonneg_tangent_map\n",
    "        self.is_symmetric = is_symmetric\n",
    "        \n",
    "    def deform(self, deltas):\n",
    "        \"\"\"\n",
    "        Deform this mesh template along its tangent map, using the provided vertex displacements.\n",
    "        \"\"\"\n",
    "        # tangent_map : precomputed rotation matrix\n",
    "        tgm = self.nonneg_tangent_map if self.is_symmetric else self.tangent_map\n",
    "        # R@delta\n",
    "        return (deltas.unsqueeze(-2) @ tgm.expand(deltas.shape[0], -1, -1, -1)).squeeze(-2)\n",
    "\n",
    "    def compute_normals(self, vertex_positions):\n",
    "        \"\"\"\n",
    "        Compute face normals from the *final* vertex positions (not deltas).\n",
    "        \"\"\"\n",
    "        a = vertex_positions[:, self.mesh.faces[:, 0]]\n",
    "        b = vertex_positions[:, self.mesh.faces[:, 1]]\n",
    "        c = vertex_positions[:, self.mesh.faces[:, 2]]\n",
    "        v1 = b - a\n",
    "        v2 = c - a\n",
    "        normal = torch.cross(v1, v2, dim=2)\n",
    "        return F.normalize(normal, dim=2)\n",
    "\n",
    "    def get_vertex_positions(self, displacement_map):\n",
    "        \"\"\"\n",
    "        Deform this mesh template using the provided UV displacement map.\n",
    "        Output: 3D vertex positions in object space.\n",
    "        \"\"\"\n",
    "        topo = self.nonneg_topo_map if self.is_symmetric else self.topo_map\n",
    "        _, displacement_map_padded = self.adjust_uv_and_texture(displacement_map)\n",
    "        if self.is_symmetric:\n",
    "            # Compensate for even symmetry in UV map\n",
    "            delta = 1/(2*displacement_map.shape[3])\n",
    "            expansion = (displacement_map.shape[3]+1)/displacement_map.shape[3]\n",
    "            topo = topo.clone()\n",
    "            topo[:, 0] = (topo[:, 0] + 1 + 2*delta - expansion)/expansion # Only for x axis\n",
    "        topo_expanded = topo.unsqueeze(0).unsqueeze(-2).expand(displacement_map.shape[0], -1, -1, -1)\n",
    "        vertex_deltas_local = grid_sample_bilinear(displacement_map_padded, topo_expanded).squeeze(-1).permute(0, 2, 1)\n",
    "        vertex_deltas = self.deform(vertex_deltas_local)\n",
    "        if self.is_symmetric:\n",
    "            # Symmetrize\n",
    "            vtx_n = torch.Tensor(vertex_deltas.shape[0], self.topo_map.shape[0], 3).to(vertex_deltas.device)\n",
    "            vtx_n[:, self.nonneg_indices] = vertex_deltas\n",
    "            vtx_n2 = vtx_n.clone()\n",
    "            vtx_n2[:, self.neg_indices] = vtx_n[:, self.pos_indices] * torch.Tensor([-1, 1, 1]).to(vtx_n.device)\n",
    "            vertex_deltas = vtx_n2 * self.symmetry_mask\n",
    "        # v' = v+R@delta\n",
    "        vertex_positions = self.mesh.vertices.unsqueeze(0) + vertex_deltas\n",
    "        return vertex_positions\n",
    "\n",
    "    def adjust_uv_and_texture(self, texture, return_texture=True):\n",
    "        \"\"\"\n",
    "        Returns the UV coordinates of this mesh template,\n",
    "        and preprocesses the provided texture to account for boundary conditions.\n",
    "        If the mesh is symmetric, the texture and UVs are adjusted accordingly.\n",
    "        \"\"\"\n",
    "        \n",
    "        if self.is_symmetric:\n",
    "            delta = 1/(2*texture.shape[3])\n",
    "            expansion = (texture.shape[3]+1)/texture.shape[3]\n",
    "            uvs = self.mesh.uvs.clone()\n",
    "            uvs[:, 0] = (uvs[:, 0] + delta)/expansion\n",
    "            \n",
    "            uvs = uvs.expand(texture.shape[0], -1, -1)\n",
    "            texture = circpad(texture, 1) # Circular padding\n",
    "        else:\n",
    "            uvs = self.mesh.uvs.expand(texture.shape[0], -1, -1)\n",
    "            texture = torch.cat((texture, texture[:, :, :, :1]), dim=3)\n",
    "            \n",
    "        return uvs, texture\n",
    "    \n",
    "    def forward_renderer(self, vertex_positions, texture, num_gpus=1, **kwargs):\n",
    "        mesh_faces = self.mesh.faces\n",
    "        mesh_face_textures = self.mesh.face_textures\n",
    "        if num_gpus > 1:\n",
    "            mesh_faces = mesh_faces.repeat(num_gpus, 1)\n",
    "            mesh_face_textures = mesh_face_textures.repeat(num_gpus, 1)\n",
    "\n",
    "        input_uvs, input_texture = self.adjust_uv_and_texture(texture)\n",
    "\n",
    "        # image, alpha, _ = renderer(points=[vertex_positions, mesh_faces],\n",
    "        #                            uv_bxpx2=input_uvs,\n",
    "        #                            texture_bx3xthxtw=input_texture,\n",
    "        #                            ft_fx3=mesh_face_textures,\n",
    "        #                            **kwargs)\n",
    "        return vertex_positions,mesh_faces,input_uvs,input_texture,mesh_face_textures\n",
    "    \n",
    "    def export_obj(self, path_prefix, vertex_positions, texture):\n",
    "        assert len(vertex_positions.shape) == 2\n",
    "        mesh_path = path_prefix + '.obj'\n",
    "        material_path = path_prefix + '.mtl'\n",
    "        material_name = os.path.basename(path_prefix)\n",
    "        \n",
    "        # Export mesh .obj\n",
    "        with open(mesh_path, 'w') as file:\n",
    "            print('mtllib ' + os.path.basename(material_path), file=file)\n",
    "            for v in vertex_positions:\n",
    "                print('v {:.5f} {:.5f} {:.5f}'.format(*v), file=file)\n",
    "            for uv in self.mesh.uvs:\n",
    "                print('vt {:.5f} {:.5f}'.format(*uv), file=file)\n",
    "            print('usemtl ' + material_name, file=file)\n",
    "            for f, ft in zip(self.mesh.faces, self.mesh.face_textures):\n",
    "                print('f {}/{} {}/{} {}/{}'.format(f[0]+1, ft[0]+1, f[1]+1, ft[1]+1, f[2]+1, ft[2]+1), file=file)\n",
    "                \n",
    "        # Export material .mtl\n",
    "        with open(material_path, 'w') as file:\n",
    "            print('newmtl ' + material_name, file=file)\n",
    "            print('Ka 1.000 1.000 1.000', file=file)\n",
    "            print('Kd 1.000 1.000 1.000', file=file)\n",
    "            print('Ks 0.000 0.000 0.000', file=file)\n",
    "            print('d 1.0', file=file)\n",
    "            print('illum 1', file=file)\n",
    "            print('map_Ka ' + material_name + '.png', file=file)\n",
    "            print('map_Kd ' + material_name + '.png', file=file)\n",
    "            \n",
    "        # Export texture\n",
    "        import imageio\n",
    "        texture = (texture.permute(1, 2, 0)*255).clamp(0, 255).cpu().byte().numpy()\n",
    "        imageio.imwrite(path_prefix + '.png', texture)\n",
    "                \n",
    "    @staticmethod\n",
    "    def _monkey_patch_dependencies():\n",
    "        if version.parse(torch.__version__) < version.parse('1.2'):\n",
    "            def torch_where_patched(*args, **kwargs):\n",
    "                if len(args) == 1:\n",
    "                    return (torch.nonzero(args[0]), )\n",
    "                else:\n",
    "                    return torch._where_original(*args)\n",
    "\n",
    "            torch._where_original = torch.where\n",
    "            torch.where = torch_where_patched\n",
    "            \n",
    "        if version.parse(torch.__version__) >= version.parse('1.5'):\n",
    "            from .monkey_patches import compute_adjacency_info_patched\n",
    "            # Monkey patch\n",
    "            kal.rep.Mesh.compute_adjacency_info = staticmethod(compute_adjacency_info_patched)\n",
    "                \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = MeshTemplate('/home/zf/vscode/3d/DR_3DFM/data/cylinder_template_mesh/0001_2_01  1022_norm_.obj')"
   ]
  },
  {
   "source": [
    "# 2. mesh变化\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "metadata": {},
     "execution_count": 97
    }
   ],
   "source": [
    "a = kal.rep.TriangleMesh.from_obj('/home/zf/vscode/3d/DR_3DFM/data/cylinder_template_mesh/uvsphere_31rings.obj', enable_adjacency=True)\n",
    "vertices = a.vertices\n",
    "y = []\n",
    "# 排序\n",
    "axis = 1\n",
    "vertices_new = sorted(vertices,key=lambda x:x[axis])\n",
    "for i in range(len(vertices_new)):\n",
    "    if i == 0 or not math.isclose(y[-1],vertices_new[i][axis],abs_tol = 0.0001):\n",
    "        # 如果接近则调出\n",
    "        y.append(vertices_new[i][axis])\n",
    "len(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "b = copy.deepcopy(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(b.vertices.shape[0]):\n",
    "    b.vertices[i] = torch.Tensor(np.array(b.vertices[i]) *  [0.8,2,0.8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "b.save_mesh('1.obj')"
   ]
  },
  {
   "source": [
    "# 3. adj测试"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import trimesh\n",
    "from scipy.sparse import coo_matrix\n",
    "\n",
    "\n",
    "\n",
    "def torch_sparse_tensor(indices, value, size):\n",
    "    coo = coo_matrix((value, (indices[:, 0], indices[:, 1])), shape=size)\n",
    "    values = coo.data\n",
    "    indices = np.vstack((coo.row, coo.col))\n",
    "\n",
    "    i = torch.tensor(indices, dtype=torch.long)\n",
    "    v = torch.tensor(values, dtype=torch.float)\n",
    "    shape = coo.shape\n",
    "\n",
    "    return torch.sparse.FloatTensor(i, v, shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Ellipsoid(object):\n",
    "\n",
    "    def __init__(self, mesh_pos, file):\n",
    "        with open(file, \"rb\") as fp:\n",
    "            fp_info = pickle.load(fp, encoding='latin1')\n",
    "\n",
    "        # shape: n_pts * 3\n",
    "        self.coord = torch.tensor(fp_info[0]) - torch.tensor(mesh_pos, dtype=torch.float)\n",
    "\n",
    "        # edges & faces & lap_idx\n",
    "        # edge: num_edges * 2\n",
    "        # faces: num_faces * 4\n",
    "        # laplace_idx: num_pts * 10\n",
    "        self.edges, self.laplace_idx = [], []\n",
    "\n",
    "        for i in range(3):\n",
    "            self.edges.append(torch.tensor(fp_info[1 + i][1][0], dtype=torch.long))\n",
    "            self.laplace_idx.append(torch.tensor(fp_info[7][i], dtype=torch.long))\n",
    "\n",
    "        # unpool index\n",
    "        # num_pool_edges * 2\n",
    "        # pool_01: 462 * 2, pool_12: 1848 * 2\n",
    "        self.unpool_idx = [torch.tensor(fp_info[4][i], dtype=torch.long) for i in range(2)]\n",
    "\n",
    "        # loops and adjacent edges\n",
    "        self.adj_mat = []\n",
    "        for i in range(1, 4):\n",
    "            # 0: np.array, 2D, pos\n",
    "            # 1: np.array, 1D, vals\n",
    "            # 2: tuple - shape, n * n\n",
    "            adj_mat = torch_sparse_tensor(*fp_info[i][1])\n",
    "            self.adj_mat.append(adj_mat)\n",
    "\n",
    "        ellipsoid_dir = os.path.dirname(file)\n",
    "        self.faces = []\n",
    "        self.obj_fmt_faces = []\n",
    "        # faces: f * 3, original ellipsoid, and two after deformations\n",
    "        for i in range(1, 4):\n",
    "            face_file = os.path.join(ellipsoid_dir, \"face%d.obj\" % i)\n",
    "            faces = np.loadtxt(face_file, dtype='|S32')\n",
    "            self.obj_fmt_faces.append(faces)\n",
    "            self.faces.append(torch.tensor(faces[:, 1:].astype(np.int) - 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "mesh_pos = torch.Tensor([0,0,0])\n",
    "obj =  Ellipsoid(mesh_pos,'/home/zf/vscode/3d/DR_3DFM/data/info_ellipsoid.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.rand((156,156))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[0.7474, 0.6870, 0.2964,  ..., 0.2934, 0.4218, 0.5662],\n",
       "        [0.9128, 0.7624, 0.7298,  ..., 0.3978, 0.3712, 0.7036],\n",
       "        [0.4203, 0.7345, 0.1927,  ..., 0.3878, 0.3320, 0.3252],\n",
       "        ...,\n",
       "        [0.9169, 0.6973, 0.8225,  ..., 0.0531, 0.8146, 0.3423],\n",
       "        [0.6804, 0.5123, 0.3365,  ..., 0.2018, 0.5788, 0.4836],\n",
       "        [0.0626, 0.2697, 0.1756,  ..., 0.0088, 0.8361, 0.9275]])"
      ]
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = obj.adj_mat[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor(indices=tensor([[  0,   0,   0,  ..., 155, 155, 155],\n",
       "                       [  0,   1,   2,  ..., 153, 154, 155]]),\n",
       "       values=tensor([ 0.3548, -0.1935, -0.2290,  ..., -0.1935, -0.2290,\n",
       "                       0.3548]),\n",
       "       size=(156, 156), nnz=1080, layout=torch.sparse_coo)"
      ]
     },
     "metadata": {},
     "execution_count": 26
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([156, 156])"
      ]
     },
     "metadata": {},
     "execution_count": 32
    }
   ],
   "source": [
    "b.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor(indices=tensor([[  0,   0,   0,  ..., 155, 155, 155],\n",
       "                       [  0,   1,   2,  ..., 153, 154, 155]]),\n",
       "       values=tensor([ 0.3548, -0.1935, -0.2290,  ..., -0.1935, -0.2290,\n",
       "                       0.3548]),\n",
       "       size=(156, 156), nnz=1080, layout=torch.sparse_coo)"
      ]
     },
     "metadata": {},
     "execution_count": 42
    }
   ],
   "source": [
    "obj.adj_mat[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}